{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45112a2c-1eb1-4b60-b3b2-4161bcdfd0b0",
   "metadata": {},
   "source": [
    "# Taller Visión por Computador Reconocimiento del Lenguaje de Señas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244c855-9ffb-48bb-aa70-e40828534705",
   "metadata": {},
   "source": [
    "## <font color= green> Primera Parte </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b99b54-4824-4401-beb5-a94e098b8b1b",
   "metadata": {},
   "source": [
    "## Deteccion de Puntos de Referencia Manuales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d48f18-2c71-40a2-a245-1cf6594f9e62",
   "metadata": {},
   "source": [
    "### Deteccion de Puntos de referencia en una imagen estatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43001351-d0b9-48ec-807f-efa5712fc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importamos las dependencias\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f5e3b-47df-4c63-a893-d0451fc0036f",
   "metadata": {},
   "source": [
    "#### Opciones de configuración de Parametros\n",
    "\n",
    "- **STATIC_IMAGE_MODE:** Si se establece en `false`, la solución trata las imágenes de entrada como una transmisión de video. Intentará detectar las manos en las primeras imágenes de entrada y, tras una detección exitosa, localiza aún más los puntos de referencia manuales. En imágenes posteriores, una vez todas max_num_hands se detectan las manos y se localizan los puntos de referencia de la mano correspondiente, simplemente rastrea esos puntos de referencia sin invocar otra detección hasta que pierde el rastro de cualquiera de las manos. Esto reduce la latencia y es ideal para procesar cuadros de video. Si se establece en `true`, la detección manual se ejecuta en cada imagen de entrada, ideal para procesar un lote de imágenes estáticas, posiblemente no relacionadas. Predeterminado a `false`.\n",
    "\n",
    "- **MAX_NUM_HANDS:** Número máximo de manos para detectar. Predeterminado a `2.`\n",
    "\n",
    "- **MODEL_COMPLEXITY:** Complejidad del modelo de punto de referencia manual: `0 o 1`. La precisión del marcador, así como la latencia de inferencia, generalmente aumentan con la complejidad del modelo. Predeterminado a `1`.\n",
    "\n",
    "- **MIN_DETECTION_CONFIDENCE:** Valor mínimo de confianza `([0.0, 1.0])` del modelo de detección manual para que la detección se considere exitosa. Predeterminado a 0.5.\n",
    "\n",
    "- **MIN_TRACKING_CONFIDENCE:** Valor mínimo de confianza `([0.0, 1.0])` del modelo de seguimiento de puntos de referencia para que los puntos de referencia manuales se consideren rastreados con éxito, o de lo contrario la detección manual se invocará automáticamente en la siguiente imagen de entrada. Establecerlo en un valor más alto puede aumentar la robustez de la solución, a expensas de una latencia más alta. Ignorado si `static_image_mode` es true, donde la detección manual simplemente se ejecuta en cada imagen. Predeterminado a `0.5.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dfe7ae-4b8b-4127-8c43-a17e29110ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaramos la ruta de la imagen a trabajar\n",
    "\n",
    "# configuramos parametos de deteccion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbd3c8-49d4-4547-9d23-1bdf5c9e5fe0",
   "metadata": {},
   "source": [
    "A continuacion cargamos la imagen utilizando opencv, realizamos un cambio de espacio de color, y graficamos la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7043e2-d564-4de6-a5c6-b81efc76ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7e706-b05c-4c50-a044-14718bb99125",
   "metadata": {},
   "source": [
    "### Mostrando los resultados\n",
    "\n",
    "El modelo realiza la deteccion de 21 puntos importantes representados como cordenadas 3d (x,y,z), de las uniones o nudillos dentro de la region de la mano, a continuacion se muestra los 21 puntos que nos retorna el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240dd011-2d96-48c3-9793-39b9ca61365f",
   "metadata": {},
   "source": [
    "![imagen](./hand_landmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd2aff-e8dc-4910-b3ad-36db6b5640f7",
   "metadata": {},
   "source": [
    "### Salida\n",
    "El estilo de denominación puede diferir ligeramente entre plataformas / idiomas.\n",
    "\n",
    "- **MULTI_HAND_LANDMARKS:** Colección de manos detectadas / rastreadas, donde cada mano se representa como una lista de 21 puntos de referencia manuales y cada punto de referencia se compone de ` x, y y z`. `x y y` se normalizan a `[0.0, 1.0]` por el ancho y la altura de la imagen respectivamente. `z` representa la profundidad de referencia con la profundidad en la muñeca como origen, y cuanto menor sea el valor, más cerca estará el punto de referencia de la cámara. La magnitud de `z` usa aproximadamente la misma escala que `x`.\n",
    "\n",
    "- **MULTI_HAND_WORLD_LANDMARKS:** Colección de manos detectadas / rastreadas, donde cada mano se representa como una lista de `21 puntos de referencia manuales en coordenadas mundiales`. Cada punto de referencia se compone de `x, y y z`: coordenadas 3D del mundo real en metros con el origen en el centro geométrico aproximado de la mano.\n",
    "\n",
    "- **MULTI_HANDEDNESS:** Recolección de la mano de las manos detectadas / rastreadas ( i.e. ¿Es una mano izquierda o derecha ). Cada mano está compuesta de label y score. label es una cadena de valor \"Left\" o \"Right\". score es la probabilidad estimada de la entrega prevista y siempre es mayor o igual que `0.5` ( y la mano opuesta tiene una probabilidad estimada de `1 - score)`.\n",
    "\n",
    "Tenga en cuenta que la capacidad de entrega se determina suponiendo que la imagen de entrada esté reflejada, es decir, tomada con una cámara frontal / selfie con imágenes volteadas horizontalmente. Si no es así, intercambie la salida de entrega en la aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3f07f-0ce7-4a9a-96ea-4a97aead9a1e",
   "metadata": {},
   "source": [
    "**Prediccion de Inferncias**\n",
    "\n",
    "Ha continuación haciendo uso de la función `process()` la cual Procesa una imagen RGB y devuelve los puntos de referencia de la mano obtenemos los `hand landmarks` de las manos detectadas en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13382afa-4010-42bc-8317-fddcce347bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb8f4f2-2ced-492f-96f2-c6132540cff8",
   "metadata": {},
   "source": [
    "### Mostrando configuración de la salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0fe93-8ba7-473c-9f1a-7cc86aa6ac8a",
   "metadata": {},
   "source": [
    "#### Obteniendo la precision e identificando la mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7bbe9-871b-463e-9fab-78492ba38890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e118dfe-ef6f-4878-b226-995544028c52",
   "metadata": {},
   "source": [
    "#### Obteniendo los marcadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc2072-e52d-4580-8831-08799ac91ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9167b23-8e72-4ece-b94e-34efc0289c44",
   "metadata": {},
   "source": [
    "#### Obteniendo cada punto en Particular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6afe76-9eb7-44bb-9c58-9457a8e5d98e",
   "metadata": {},
   "source": [
    "![imagen](./hand_landmarks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bbcb7-2a48-4e06-ac24-cbf2b46fe456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f791000-1b49-4ed9-b033-caca3eaec15a",
   "metadata": {},
   "source": [
    "### Dibujando y Mostrando los Puntos y sus conexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1c077-3817-4401-bc4f-4c181a5c43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9757d-0109-4d2f-9ae6-14e88afb28e9",
   "metadata": {},
   "source": [
    "### Dibujando las cajas delimitadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fde6eb-4d29-4c2e-af43-168d0c74881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315ff31-6b41-4c1e-9d50-0390eb140cd2",
   "metadata": {},
   "source": [
    "### Dibujando y mostrando los puntos y sus cajas delimitadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd96d2-3cbf-44c5-b528-bf755ba8b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9e7f4-9bfc-471e-9b7b-cca63f67d1f2",
   "metadata": {},
   "source": [
    "### Dibujando y mostrando los puntos, cajas delimitadoras, mano correspondiente y precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c65e94-bb6c-4c25-a4ba-7949bbac1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b498b12-ead3-42a4-99ba-e58403d08acd",
   "metadata": {},
   "source": [
    "## Deteccion de Puntos de Referencia en Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859457e-d16f-4b24-b81a-a26a96b2b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3806b-38f9-4752-ae10-df9f9d62d8b0",
   "metadata": {},
   "source": [
    "### Programa Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cef617-3288-41f3-801c-f927522e39c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importacion de librerias\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "\n",
    "## referenciando metodos necesarios\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# configurando parametros de deteccion\n",
    "hands = mp_hands.Hands(max_num_hands=2,\n",
    "                       min_detection_confidence=0.8, \n",
    "                       min_tracking_confidence=0.8\n",
    "                      )\n",
    "# creacion de ventanas para mostrar los resultados\n",
    "cv.namedWindow(\"MediaPipe Hands\", cv.WINDOW_NORMAL)\n",
    "\n",
    "## *****************************************************************************\n",
    "## Funcion para dibujar los puntos y sus conexiones\n",
    "def hand_detect(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "    \n",
    "    if result.multi_hand_landmarks: \n",
    "        \n",
    "        img = draw_box(result, img)\n",
    "        \n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(img, \n",
    "                                      hand_landmarks, \n",
    "                                      mp_hands.HAND_CONNECTIONS,\n",
    "                                      mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                      mp_drawing_styles.get_default_hand_connections_style()\n",
    "                                      )\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    return img\n",
    "## *****************************************************************************\n",
    "## Funcion para dibujar los cuadros delimitadores\n",
    "def draw_box(result, img):\n",
    "    \n",
    "    hand_id, hand_score = score(result)\n",
    "    cont =0\n",
    "    for hand_landmarks in result.multi_hand_landmarks:\n",
    "        xlist=[]\n",
    "        ylist=[]\n",
    "        for id, lm in enumerate(hand_landmarks.landmark):\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            xlist.append(cx)\n",
    "            ylist.append(cy)\n",
    "\n",
    "        xmin, xmax = min(xlist), max(xlist)\n",
    "        ymin, ymax = min(ylist), max(ylist)\n",
    "        \n",
    "        cv.rectangle(img, (xmin-20, ymin-20), (xmax+20, ymax+20),(0, 255, 0), 2)\n",
    "        text = str(hand_id[cont])+\" \"+str(hand_score[cont])+\"%\"\n",
    "        cv.putText(img, \n",
    "                    text, \n",
    "                    (xmin-20, ymin-20), \n",
    "                    cv.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, \n",
    "                    (255,0,0),2)\n",
    "        cont+=1\n",
    "        \n",
    "    return img\n",
    "\n",
    "## *****************************************************************************\n",
    "## Funcion para encontrar la Mano correspondiente y su porcentaje de presicion en la deteccion\n",
    "def score(result):\n",
    "    hand_id=[]\n",
    "    hand_score = []\n",
    "    for hand in result.multi_handedness:\n",
    "        \n",
    "        for id, lm in enumerate(hand.classification):\n",
    "            hand_id.append(lm.label)\n",
    "            hand_score.append(int(lm.score*100))\n",
    "            \n",
    "    return hand_id, hand_score\n",
    "               \n",
    "## *****************************************************************************\n",
    "## ----------- CODIGO PRINCIPAL--------------------------\n",
    "## creacion del Objeto captura de video \n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read() \n",
    "    \n",
    "    if ret:\n",
    "        frame = cv.flip(frame, 1)\n",
    "        img_proces = frame.copy()\n",
    "        image = hand_detect(img_proces)\n",
    "        cv.imshow(\"MediaPipe Hands\", image)\n",
    "        \n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf03db-f9d9-4e3f-b38f-0d9a8f1cfab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0be50e-264f-4ca3-ae20-bf1b2c516e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444473a7-9583-4f9b-9872-49e5ad3b826e",
   "metadata": {},
   "source": [
    "## Proyecto Capturar la imagen de la mano para crear datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252c928-dd53-4b15-a00e-0ff9a8154af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
